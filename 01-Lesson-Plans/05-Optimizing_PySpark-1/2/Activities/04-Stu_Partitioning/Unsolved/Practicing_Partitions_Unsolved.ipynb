{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w1m9uEbLTfhq"
      },
      "outputs": [],
      "source": [
        "# Activate Spark in our Colab notebook.\n",
        "import os\n",
        "# Find the latest version of spark 3.0  from http://www.apache.org/dist/spark/ and enter as the spark version\n",
        "# For example: 'spark-3.2.2'\n",
        "spark_version = 'spark-3.2.2'\n",
        "# spark_version = 'spark-3.<enter version>'\n",
        "os.environ['SPARK_VERSION']=spark_version\n",
        "\n",
        "# Install Spark and Java\n",
        "!apt-get update\n",
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "!wget -q http://www.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop3.2.tgz\n",
        "!tar xf $SPARK_VERSION-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "# Set Environment Variables\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop3.2\"\n",
        "\n",
        "# Start a SparkSession\n",
        "import findspark\n",
        "findspark.init()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wdpzXrYLTgcq"
      },
      "outputs": [],
      "source": [
        "# Import packages\n",
        "from pyspark.sql import SparkSession\n",
        "import time\n",
        "\n",
        "# Create a SparkSession\n",
        "spark = SparkSession.builder.appName(\"SparkSQL\").getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SyGdKF4mTguN"
      },
      "outputs": [],
      "source": [
        "# Read in data from S3 Bucket\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "daHsHUbSTzaj"
      },
      "outputs": [],
      "source": [
        "#Create temp view named \"delays\"\n",
        "\n",
        "# Start the runtime\n",
        "\n",
        "# Using spark.sql write a query that gives you the total distance and the count of every unique Origin, Dest combination\n",
        "\n",
        "# Print out the runtime."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EVQQPzgiUgTg"
      },
      "outputs": [],
      "source": [
        "# Write out the data in parquet format\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1fjWZBkMUuIQ"
      },
      "outputs": [],
      "source": [
        "# Read in our new parquet formatted data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O9Vj-1tAVMxZ"
      },
      "outputs": [],
      "source": [
        "# Convert the dataframe to a view.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W1upPNu4VFnm"
      },
      "outputs": [],
      "source": [
        "# Start the runtime\n",
        "\n",
        "# Run the same query as above here\n",
        "\n",
        "# Print out the runtime\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RxtycEtOVQrZ"
      },
      "outputs": [],
      "source": [
        "# Write out your parquet data, partitioning on the Origin column\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TMpsNLamXM9N"
      },
      "outputs": [],
      "source": [
        "# Read in our new parquet formatted data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KX3wglAtWEbI"
      },
      "outputs": [],
      "source": [
        "# Convert the dataframe to a view.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LOR5HfhRVzmG"
      },
      "outputs": [],
      "source": [
        "# Start the runtime\n",
        "\n",
        "# Run your query against your partitioned data one more time.\n",
        "\n",
        "# Print out the runtime.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w1LbeemvWsRa"
      },
      "outputs": [],
      "source": [
        "# Start  the runtime\n",
        "\n",
        "# Filter the data on something that selects your partition choice.\n",
        "\n",
        "# Print out the runtime.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e3wGOJK3Xrnu"
      },
      "outputs": [],
      "source": [
        "# Start  the runtime\n",
        "\n",
        "# Filter the data on something that has nothing to do with your partition choice.\n",
        "\n",
        "# Print out the runtime."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Practicing_Partitions_Unsolved.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
